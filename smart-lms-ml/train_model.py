import os
import pandas as pd
import pyodbc
from dotenv import load_dotenv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# --- 1. Cáº¤U HÃŒNH VÃ€ Káº¾T Ná»I CSDL ---

dotenv_path = os.path.join(os.path.dirname(__file__), '..', 'smart-lms-backend', '.env')
load_dotenv(dotenv_path=dotenv_path)

DB_SERVER = os.getenv('DB_SERVER')
DB_NAME = os.getenv('DB_NAME')
DB_USER = os.getenv('DB_USER')
DB_PASSWORD = os.getenv('DB_PASSWORD')
DB_PORT = os.getenv('DB_PORT')

conn_str = (
    f'DRIVER={{ODBC Driver 17 for SQL Server}};'
    f'SERVER={DB_SERVER},{DB_PORT};'
    f'DATABASE={DB_NAME};'
    f'UID={DB_USER};'
    f'PWD={DB_PASSWORD};'
)

def fetch_data():
    """HÃ m Ä‘á»c dá»¯ liá»‡u tá»« báº£ng StudentBehaviors."""
    print("Báº¯t Ä‘áº§u Ä‘á»c dá»¯ liá»‡u tá»« CSDL MSSQL...")
    try:
        cnxn = pyodbc.connect(conn_str)
        # âœ… FIX: Query chá»‰ láº¥y cÃ¡c columns cÃ²n láº¡i (khÃ´ng cÃ³ DeviceType, SatisfactionLevel)
        query = """
        SELECT StudyHours, AssignmentCompletionRate, QuizScore_Avg, 
               PlatformEngagement_Minutes, LearningStyle, Motivation, StressLevel, FinalGrade 
        FROM StudentBehaviors
        """
        df = pd.read_sql(query, cnxn)
        cnxn.close()
        print(f"âœ… Äá»c thÃ nh cÃ´ng {len(df)} dÃ²ng dá»¯ liá»‡u.")
        return df
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c dá»¯ liá»‡u: {e}")
        return None

def preprocess_data(df):
    """HÃ m tiá»n xá»­ lÃ½ dá»¯ liá»‡u Ä‘á»ƒ chuáº©n bá»‹ cho mÃ´ hÃ¬nh."""
    print("\nBáº¯t Ä‘áº§u tiá»n xá»­ lÃ½ dá»¯ liá»‡u...")
    
    # âœ… Debug: Kiá»ƒm tra dá»¯ liá»‡u thá»±c táº¿
    print(f"ğŸ“Š Tá»•ng sá»‘ dÃ²ng: {len(df)}")
    print(f"ğŸ“Š LearningStyle unique values: {sorted(df['LearningStyle'].unique())}")
    print(f"ğŸ“Š FinalGrade range: {df['FinalGrade'].min()} - {df['FinalGrade'].max()}")
    print(f"ğŸ“Š FinalGrade unique values: {sorted(df['FinalGrade'].unique())}")
    print(f"ğŸ“Š FinalGrade distribution:\n{df['FinalGrade'].value_counts().sort_index()}")
    
    # âœ… Xá»­ lÃ½ LearningStyle
    df['LearningStyle'] = df['LearningStyle'].fillna('0')
    
    try:
        df['LearningStyle'] = df['LearningStyle'].astype(str).str.strip()
        df['LearningStyle'] = pd.to_numeric(df['LearningStyle'], errors='coerce')
        df['LearningStyle'] = df['LearningStyle'].fillna(0).astype(int)
    except:
        print("âš ï¸  Warning: LearningStyle contains non-numeric values, converting to categories")
        df['LearningStyle'] = df['LearningStyle'].astype('category').cat.codes
    
    print(f"ğŸ“Š LearningStyle after processing: {sorted(df['LearningStyle'].unique())}")
    
    # âœ… FIX: Logic phÃ¢n loáº¡i Ä‘Ãºng theo thang 4.0
    def grade_to_label(grade):
        """
        PhÃ¢n loáº¡i grade theo thang 4.0 chuáº©n giÃ¡o dá»¥c
        4.0 = Xuáº¥t sáº¯c, 3.0 = KhÃ¡, 2.0 = Trung bÃ¬nh, 1.0 = Yáº¿u, 0.0 = KÃ©m
        """
        if pd.isna(grade):
            return 'Yáº¿u'
        
        if grade >= 3.5: return 'Xuáº¥t sáº¯c'        # 3.5-4.0 = A/A+  
        elif grade >= 2.5: return 'Giá»i'       # 2.5-3.4 = B
        elif grade >= 1.5: return 'KhÃ¡' # 1.5-2.4 = C
        elif grade >= 0.5: return 'Trung bÃ¬nh'       # 0.5-1.4 = D
        else: return 'Trung bÃ¬nh'                    # 0.0-0.4 = F

    df['GradeLabel'] = df['FinalGrade'].apply(grade_to_label)
    
    # âœ… PhÃ¢n loáº¡i features
    numeric_features = ['StudyHours', 'AssignmentCompletionRate', 'QuizScore_Avg', 
                       'PlatformEngagement_Minutes', 'Motivation', 'StressLevel']
    categorical_features = ['LearningStyle']
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        remainder='drop'
    )
    
    feature_columns = numeric_features + categorical_features
    X = df[feature_columns].copy()
    y = df['GradeLabel']
    
    print(f"ğŸ“Š Features shape: {X.shape}")
    print(f"ğŸ“Š Target distribution:\n{y.value_counts()}")
    print("âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t.")
    
    return X, y, preprocessor

def train_and_save_models(X, y, preprocessor):
    """HÃ m huáº¥n luyá»‡n vÃ  lÆ°u cáº£ hai mÃ´ hÃ¬nh K-Means vÃ  Random Forest."""
    
    # --- MÃ´ hÃ¬nh 1: K-Means Clustering ---
    print("\n--- Huáº¥n luyá»‡n mÃ´ hÃ¬nh PhÃ¢n cá»¥m K-Means ---")
    
    kmeans_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('cluster', KMeans(n_clusters=4, random_state=42, n_init=10))
    ]) 
    
    kmeans_pipeline.fit(X)
    print("âœ… Huáº¥n luyá»‡n K-Means hoÃ n táº¥t.")
    
    # LÆ°u pipeline cá»§a K-Means
    joblib.dump(kmeans_pipeline, 'student_cluster_model.pkl')
    print("ğŸ’¾ MÃ´ hÃ¬nh PhÃ¢n cá»¥m Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o file 'student_cluster_model.pkl'")

    # --- MÃ´ hÃ¬nh 2: Random Forest Classifier ---
    print("\n--- Huáº¥n luyá»‡n mÃ´ hÃ¬nh Dá»± Ä‘oÃ¡n Random Forest ---")

    # Kiá»ƒm tra distribution cá»§a target
    print(f"ğŸ“Š Target classes: {y.value_counts()}")
    
    # Chia dá»¯ liá»‡u - chá»‰ stratify náº¿u cÃ³ nhiá»u hÆ¡n 1 class
    unique_classes = y.nunique()
    if unique_classes > 1:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
    else:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        print("âš ï¸  Warning: Chá»‰ cÃ³ 1 class trong target, khÃ´ng thá»ƒ stratify")
    
    # Táº¡o pipeline cho Random Forest
    rf_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
    
    rf_pipeline.fit(X_train, y_train)
    print("âœ… Huáº¥n luyá»‡n Random Forest hoÃ n táº¥t.")
    
    # ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm thá»­
    y_pred = rf_pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\nğŸ“Š Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm thá»­: {accuracy:.2f}")
    print("ğŸ“„ BÃ¡o cÃ¡o phÃ¢n loáº¡i chi tiáº¿t:")
    print(classification_report(y_test, y_pred))

    # LÆ°u pipeline cá»§a Random Forest
    joblib.dump(rf_pipeline, 'grade_prediction_model.pkl')
    print("ğŸ’¾ MÃ´ hÃ¬nh Dá»± Ä‘oÃ¡n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o file 'grade_prediction_model.pkl'")

# --- CHáº Y CHÃNH ---
if __name__ == "__main__":
    df = fetch_data()
    if df is not None:
        X, y, preprocessor = preprocess_data(df)
        train_and_save_models(X, y, preprocessor)
