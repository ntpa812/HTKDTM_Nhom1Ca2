import os
import pandas as pd
import pyodbc
from dotenv import load_dotenv
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# --- 1. Cáº¤U HÃŒNH VÃ€ Káº¾T Ná»I CSDL ---

dotenv_path = os.path.join(os.path.dirname(__file__), '..', 'smart-lms-backend', '.env')
load_dotenv(dotenv_path=dotenv_path)

DB_SERVER = os.getenv('DB_SERVER')
DB_NAME = os.getenv('DB_NAME')
DB_USER = os.getenv('DB_USER')
DB_PASSWORD = os.getenv('DB_PASSWORD')
DB_PORT = os.getenv('DB_PORT')


conn_str = (
    f'DRIVER={{ODBC Driver 17 for SQL Server}};'
    f'SERVER={DB_SERVER},{DB_PORT};'
    f'DATABASE={DB_NAME};'
    f'UID={DB_USER};'
    f'PWD={DB_PASSWORD};'
)

def fetch_data():
    """HÃ m Ä‘á»c dá»¯ liá»‡u tá»« báº£ng StudentBehaviors."""
    print("Báº¯t Ä‘áº§u Ä‘á»c dá»¯ liá»‡u tá»« CSDL MSSQL...")
    try:
        cnxn = pyodbc.connect(conn_str)
        query = "SELECT UserID, StudyHours, AssignmentCompletionRate, QuizScore_Avg, PlatformEngagement_Minutes, LearningStyle, Motivation, StressLevel, FinalGrade FROM StudentBehaviors"
        df = pd.read_sql(query, cnxn)
        cnxn.close()
        print(f"âœ… Äá»c thÃ nh cÃ´ng {len(df)} dÃ²ng dá»¯ liá»‡u.")
        return df
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c dá»¯ liá»‡u: {e}")
        return None

# --- 2. TIá»€N Xá»¬ LÃ Dá»® LIá»†U ---

def preprocess_data(df):
    """HÃ m tiá»n xá»­ lÃ½ dá»¯ liá»‡u Ä‘á»ƒ chuáº©n bá»‹ cho mÃ´ hÃ¬nh."""
    print("\nBáº¯t Ä‘áº§u tiá»n xá»­ lÃ½ dá»¯ liá»‡u...")
    
    # XÃ¡c Ä‘á»‹nh cÃ¡c cá»™t sá»‘ vÃ  cá»™t phÃ¢n loáº¡i
    numeric_features = ['StudyHours', 'AssignmentCompletionRate', 'QuizScore_Avg', 'PlatformEngagement_Minutes', 'Motivation', 'StressLevel']
    categorical_features = ['LearningStyle']
    
    # Táº¡o má»™t "Ä‘Æ°á»ng á»‘ng" xá»­ lÃ½:
    # - Vá»›i cá»™t sá»‘: Chuáº©n hÃ³a (Ä‘Æ°a vá» cÃ¹ng má»™t thang Ä‘o)
    # - Vá»›i cá»™t phÃ¢n loáº¡i: MÃ£ hÃ³a One-Hot (biáº¿n 'Visual', 'Auditory' thÃ nh cÃ¡c cá»™t 0/1)
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
        ])
    
    # Chuyá»ƒn Ä‘á»•i cá»™t má»¥c tiÃªu 'FinalGrade' thÃ nh cÃ¡c nhÃ£n sá»‘
    # Giáº£ sá»­ Ä‘iá»ƒm lÃ  tá»« 0-100
    def grade_to_label(grade):
        if grade >= 85: return 'Giá»i'
        if grade >= 70: return 'KhÃ¡'
        if grade >= 50: return 'Trung bÃ¬nh'
        return 'Yáº¿u'

    df['GradeLabel'] = df['FinalGrade'].apply(grade_to_label)
    
    X = df.drop(columns=['UserID', 'FinalGrade', 'GradeLabel'])
    y = df['GradeLabel']
    
    print("âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t.")
    return X, y, preprocessor

# --- 3. HUáº¤N LUYá»†N VÃ€ LÆ¯U MÃ” HÃŒNH ---

def train_and_save_models(X, y, preprocessor):
    """HÃ m huáº¥n luyá»‡n vÃ  lÆ°u cáº£ hai mÃ´ hÃ¬nh K-Means vÃ  Random Forest."""
    
    # --- MÃ´ hÃ¬nh 1: K-Means Clustering ---
    print("\n--- Huáº¥n luyá»‡n mÃ´ hÃ¬nh PhÃ¢n cá»¥m K-Means ---")
    
    # Táº¡o pipeline cho K-Means: Tiá»n xá»­ lÃ½ -> Cháº¡y thuáº­t toÃ¡n
    # ChÃºng ta sáº½ chia sinh viÃªn thÃ nh 4 nhÃ³m
    kmeans_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                      ('cluster', KMeans(n_clusters=4, random_state=42, n_init=10))]) 
    
    kmeans_pipeline.fit(X)
    print("âœ… Huáº¥n luyá»‡n K-Means hoÃ n táº¥t.")
    
    # LÆ°u pipeline cá»§a K-Means
    joblib.dump(kmeans_pipeline, 'student_cluster_model.pkl')
    print("ğŸ’¾ MÃ´ hÃ¬nh PhÃ¢n cá»¥m Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o file 'student_cluster_model.pkl'")

    # --- MÃ´ hÃ¬nh 2: Random Forest Classifier ---
    print("\n--- Huáº¥n luyá»‡n mÃ´ hÃ¬nh Dá»± Ä‘oÃ¡n Random Forest ---")

    # Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n (80%) vÃ  táº­p kiá»ƒm thá»­ (20%)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # Táº¡o pipeline cho Random Forest: Tiá»n xá»­ lÃ½ -> Cháº¡y thuáº­t toÃ¡n
    rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                  ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])
    
    rf_pipeline.fit(X_train, y_train)
    print("âœ… Huáº¥n luyá»‡n Random Forest hoÃ n táº¥t.")
    
    # ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm thá»­
    y_pred = rf_pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\nğŸ“Š Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm thá»­: {accuracy:.2f}")
    print("ğŸ“„ BÃ¡o cÃ¡o phÃ¢n loáº¡i chi tiáº¿t:")
    print(classification_report(y_test, y_pred))

    # LÆ°u pipeline cá»§a Random Forest
    joblib.dump(rf_pipeline, 'grade_prediction_model.pkl')
    print("ğŸ’¾ MÃ´ hÃ¬nh Dá»± Ä‘oÃ¡n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o file 'grade_prediction_model.pkl'")


# --- CHáº Y CHÃNH ---
if __name__ == "__main__":
    df = fetch_data()
    if df is not None:
        X, y, preprocessor = preprocess_data(df)
        train_and_save_models(X, y, preprocessor)
